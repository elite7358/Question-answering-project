{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 26 21:55:40 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b7b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet transformers==4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d604b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet https://github.com/PyTorchLightning/pytorch-lightning/releases/download/1.2.6/pytorch-lightning-1.2.6.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7e8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet tokenizers==0.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6043e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet sentencepiece==0.1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b19e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97aa54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown as gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from termcolor import colored\n",
    "import textwrap\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU's available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPU's available: \", len(physical_devices))\n",
    "\n",
    "if(len(physical_devices)>0):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd09986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ee8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip - bio-QA.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eafd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"BioASQ/BioASQ-train-factoid-4b.json\").open() as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb64290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'version'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe6b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742e8075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f3ed067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paragraphs', 'title'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b6575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f23436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68358bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['data'][0]['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d48bde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'id': '52bf208003868f1b06000019_002',\n",
       "   'question': 'What is the inheritance pattern of Li–Fraumeni syndrome?',\n",
       "   'answers': [{'text': 'autosomal dominant', 'answer_start': 213}]}],\n",
       " 'context': 'Balanced t(11;15)(q23;q15) in a TP53+/+ breast cancer patient from a Li-Fraumeni syndrome family. Li-Fraumeni Syndrome (LFS) is characterized by early-onset carcinogenesis involving multiple tumor types and shows autosomal dominant inheritance. Approximately 70% of LFS cases are due to germline mutations in the TP53 gene on chromosome 17p13.1. Mutations have also been found in the CHEK2 gene on chromosome 22q11, and others have been mapped to chromosome 11q23. While characterizing an LFS family with a documented defect in TP53, we found one family member who developed bilateral breast cancer at age 37 yet was homozygous for wild-type TP53. Her mother also developed early-onset primary bilateral breast cancer, and a sister had unilateral breast cancer and a soft tissue sarcoma. Cytogenetic analysis using fluorescence in situ hybridization of a primary skin fibroblast cell line revealed that the patient had a novel balanced reciprocal translocation between the long arms of chromosomes 11 and 15: t(11;15)(q23;q15). This translocation was not present in a primary skin fibroblast cell line from a brother with neuroblastoma, who was heterozygous for the TP53 mutation. There was no evidence of acute lymphoblastic leukemia in either the patient or her mother, although a nephew did develop leukemia and died in childhood. These data may implicate the region at breakpoint 11q23 and/or 15q15 as playing a significant role in predisposition to breast cancer development.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c703a71",
   "metadata": {},
   "outputs": [],
   "source": [
    " def extract_questions_and_answers(path = Path):\n",
    "    with path.open() as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    questions = data['data'][0]['paragraphs']\n",
    "     \n",
    "    data_rows = []\n",
    "    \n",
    "    for question in questions:\n",
    "        context = question['context']\n",
    "\n",
    "        for question_and_answers in question['qas']:\n",
    "            question = question_and_answers['question']\n",
    "            answers = question_and_answers['answers']\n",
    "\n",
    "            for answer in answers:\n",
    "                answer_text = answer['text']\n",
    "                answer_start = answer['answer_start']\n",
    "                answer_end = answer['answer_start'] + len(answer_text)\n",
    "                    \n",
    "                data_rows.append({\n",
    "                     \"question\" : question,\n",
    "                     \"context\"  : context,\n",
    "                     \"answer_text\" : answer_text,\n",
    "                     \"answer_start\" : answer_start,\n",
    "                     \"answer_end\" : answer_end\n",
    "                     })\n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ed2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_questions_and_answers(Path(\"BioASQ/BioASQ-train-factoid-4b.json\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97477a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('BioASQ/BioASQ-train-factoid-4b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-5b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-6b.json')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = sorted(list(Path(\"BioASQ/\").glob(\"BioASQ-train-*\")))\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "114f80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = []\n",
    "\n",
    "for path in paths:\n",
    "    df_new.append(extract_questions_and_answers(path))\n",
    "    \n",
    "df = pd.concat(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f181918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5938b111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12988, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = [\"context\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2582, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8683b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b0ddc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.context.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "383b90c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question        What is the characteristic feature of the Dyke...\n",
       "context         Left hemisphere and male sex dominance of cere...\n",
       "answer_text                                  cerebral hemiatrophy\n",
       "answer_start                                                  130\n",
       "answer_end                                                    150\n",
       "Name: 240, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = df.iloc[240]\n",
    "sample_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2cecc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b27c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(sample_question[\"question\"],sample_question[\"context\"], max_length = 396, padding = \"max_length\", \n",
    "          truncation = \"only_second\", return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "114f5110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a63ff6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>',\n",
       " 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f7642fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e914e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the characteristic feature of the Dyke-Davidoff-Masson syndrome.</s> Left hemisphere and male sex dominance of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome). Although radiological findings of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome) are well known, there is no systematic study about the gender and the affected side in this syndrome. Brain images in 26 patients (mean aged 11) with cerebral hemiatrophy were retrospectively reviewed. Nineteen patients (73.5%) were male and seven patients (26.5%) were female. Left hemisphere involvement was seen in 18 patients (69.2%) and right hemisphere involvement was seen in eight patients (30.8%). We conclude that male gender and left side involvement are frequent in cerebral hemiatrophy disease.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85705f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_encoding = tokenizer(\n",
    "     sample_question['answer_text'],\n",
    "     max_length=32,\n",
    "     padding='max_length',\n",
    "     truncation=True,\n",
    "     return_attention_mask=True,\n",
    "     add_special_tokens=True,\n",
    "     return_tensors=\"pt\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31d54acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerebral hemiatrophy</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_encoding['input_ids'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c408d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = answer_encoding[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f50386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5edc7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels == 0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02d9bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c8ca551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeData(Dataset):\n",
    "    \n",
    "    def __init__(self, data:pd.DataFrame, tokenizer:T5Tokenizer, source_max_token_len: int =369, target_max_token_len: int =32):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        \n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        source_encoding = tokenizer(data_row['question'], data_row['context'], max_length=self.source_max_token_len,\n",
    "                                        padding='max_length', truncation=\"only_second\", return_attention_mask=True,\n",
    "                                        add_special_tokens=True, return_tensors=\"pt\")\n",
    "        \n",
    "        target_encoding = tokenizer(data_row['answer_text'], max_length=self.target_max_token_len, padding='max_length',\n",
    "                                        truncation=True, return_attention_mask=True, add_special_tokens=True,\n",
    "                                        return_tensors=\"pt\")\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(question = data_row[\"question\"], context = data_row[\"context\"], answer_text = data_row[\"answer_text\"],\n",
    "                       input_ids = source_encoding[\"input_ids\"].flatten(), \n",
    "                       attention_mask = source_encoding[\"attention_mask\"].flatten(), labels = labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed91aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = TokenizeData(df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b5edb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the inheritance pattern of Li–Fraumeni syndrome?\n",
      "answers:  autosomal dominant\n",
      "input_ids:  tensor([  363,    19,     8, 28915,  3275,    13,  1414,   104,   371,  6340])\n",
      "labels:  tensor([ 1510, 10348,   138, 12613,     1,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "for data in sample_dataset:\n",
    "    print(\"question: \", data[\"question\"])\n",
    "    print(\"answers: \",data[\"answer_text\"])\n",
    "    print(\"input_ids: \", data[\"input_ids\"][:10])\n",
    "    print(\"labels: \", data[\"labels\"][:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d094b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51b90f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2452, 5)\n",
      "(130, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cb38dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateData(pl.LightningDataModule):\n",
    "    def __init__(self, train_df: pd.DataFrame, test_df: pd.DataFrame, tokenizer:T5Tokenizer, batch_size: int = 8,\n",
    "                    source_max_token_len: int = 396, target_max_token_len: int = 32):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "   \n",
    "    def setup(self):\n",
    "        \n",
    "        self.train_dataset = TokenizeData(self.train_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "        self.test_dataset = TokenizeData(self.test_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d23bc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 6\n",
    "\n",
    "data_module = CreateData(train_df, val_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0c666ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52c131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "584e3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32128])\n"
     ]
    }
   ],
   "source": [
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff1ffd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0636, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "094c531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "   \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \n",
    "        output = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return output.loss, output.logits\n",
    "   \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n",
    "       \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=0.0001)\n",
    "        return optimizer      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27b747a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a3ac198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", filename=\"best-checkpoint\",filepath=\"./\", save_top_k=1, verbose=True,\\n                                        monitor=\"val_loss\", mode=\"min\")'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", filename=\"best-checkpoint\",filepath=\"./\", save_top_k=1, verbose=True,\n",
    "                                        monitor=\"val_loss\", mode=\"min\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dd64375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(checkpoint_callback=checkpoint_callback, max_epochs=NUM_EPOCHS, gpus=1, progress_bar_refresh_rate = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bb54d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df4b14bd8c4c77a6fab84c7f432fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83fd3726c47463bad2ce42c42339dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 612: val_loss reached 0.24086 (best 0.24086), saving model to \"/data/user/ankitk/NLP/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1225: val_loss reached 0.20731 (best 0.20731), saving model to \"/data/user/ankitk/NLP/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1838: val_loss reached 0.20346 (best 0.20346), saving model to \"/data/user/ankitk/NLP/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 2451: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 3064: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 3677: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60dc839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97af34c60bf4a8f884fe8454a742bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.2034628689289093}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2034628689289093}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "249132d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trained_model = QAModel.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c64dc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "928ad149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding=tokenizer(\n",
    "            question[\"question\"],\n",
    "            question['context'],\n",
    "            max_length = 396,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "       )\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask=source_encoding[\"attention_mask\"],\n",
    "        num_beams=1,  # greedy search\n",
    "        max_length=80,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty = 1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache=True)\n",
    "\n",
    "    preds = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "             for generated_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which calcium channels does ethosuximide target?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = val_df.iloc[20]\n",
    "sample_question[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-type calcium channels'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question[\"answer_text\"]  # Label Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-type calcium channels'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question)  # Predicted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = val_df.iloc[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcription factor EB (TFEB)'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcription factor EB (TFEB)'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp2021]",
   "language": "python",
   "name": "conda-env-nlp2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
