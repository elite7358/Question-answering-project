{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  3 19:08:19 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| N/A   27C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALLING ALL THE REQUIRED PACKAGES\n",
    " <B> We need to install pytorch lightning to build the model which we can do using line command as </b>\n",
    " <b> !pip install pytorch-lightning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b7b2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /data/user/home/ankitk/.local/lib/python3.8/site-packages (4.13.0.dev0)\n",
      "Requirement already satisfied: requests in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: sacremoses in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: click in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tokenizers in /data/user/home/ankitk/.local/lib/python3.8/site-packages (0.10.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /data/user/home/ankitk/.local/lib/python3.8/site-packages (0.1.94)\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==4.1.1\n",
    "#!pip install tokenizers==0.9.4\n",
    "#!pip install sentencepiece==0.1.94\n",
    "\n",
    "!pip install transformers\n",
    "!pip install tokenizers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d604b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch-lightning in /data/user/home/ankitk/.local/lib/python3.8/site-packages (1.2.6)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (2021.7.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (4.61.2)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from pytorch-lightning) (0.6.0)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: torch>=1.4 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (1.7.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (1.19.5)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pytorch-lightning) (2.5.0)\n",
      "Requirement already satisfied: requests in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.34.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.33.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: six in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch-lightning) (2021.5.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
      "Requirement already satisfied: packaging in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from torchmetrics>=0.2.0->pytorch-lightning) (21.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /data/user/home/ankitk/.local/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning) (1.7.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/rc/apps/rc/software/Anaconda3/2020.11/envs/nlp2021/lib/python3.8/site-packages (from packaging->torchmetrics>=0.2.0->pytorch-lightning) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --quiet https://github.com/PyTorchLightning/pytorch-lightning/releases/download/1.2.6/pytorch-lightning-1.2.6.tar.gz\n",
    "\n",
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING ALL THE REQUIRED MODULES TO RUN THIS iPynb File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97aa54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU's available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPU's available: \", len(physical_devices))\n",
    "\n",
    "if(len(physical_devices)>0):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We seed everything to 0 using pytorch lightning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ee8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip - bio-QA.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Importing all the training data from the json file from the file directory</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eafd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"BioASQ/BioASQ-train-factoid-4b.json\").open() as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will have a look at our data using pandas and creating a pandas dataframe using some analysis on the data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'version'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe6b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742e8075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3ed067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paragraphs', 'title'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b6575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f23436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68358bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['data'][0]['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d48bde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'id': '52bf208003868f1b06000019_002',\n",
       "   'question': 'What is the inheritance pattern of Li–Fraumeni syndrome?',\n",
       "   'answers': [{'text': 'autosomal dominant', 'answer_start': 213}]}],\n",
       " 'context': 'Balanced t(11;15)(q23;q15) in a TP53+/+ breast cancer patient from a Li-Fraumeni syndrome family. Li-Fraumeni Syndrome (LFS) is characterized by early-onset carcinogenesis involving multiple tumor types and shows autosomal dominant inheritance. Approximately 70% of LFS cases are due to germline mutations in the TP53 gene on chromosome 17p13.1. Mutations have also been found in the CHEK2 gene on chromosome 22q11, and others have been mapped to chromosome 11q23. While characterizing an LFS family with a documented defect in TP53, we found one family member who developed bilateral breast cancer at age 37 yet was homozygous for wild-type TP53. Her mother also developed early-onset primary bilateral breast cancer, and a sister had unilateral breast cancer and a soft tissue sarcoma. Cytogenetic analysis using fluorescence in situ hybridization of a primary skin fibroblast cell line revealed that the patient had a novel balanced reciprocal translocation between the long arms of chromosomes 11 and 15: t(11;15)(q23;q15). This translocation was not present in a primary skin fibroblast cell line from a brother with neuroblastoma, who was heterozygous for the TP53 mutation. There was no evidence of acute lymphoblastic leukemia in either the patient or her mother, although a nephew did develop leukemia and died in childhood. These data may implicate the region at breakpoint 11q23 and/or 15q15 as playing a significant role in predisposition to breast cancer development.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We are creating a function to create the dataframe with these specific columns in our dataframe - <br> i) question <br> (ii) context/ or paragraph named as context <br> (iii) answer text <br> (iv) answer starting index <br> (v) answer end index </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_questions_and_answers(path = Path):\n",
    "    with path.open() as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    questions = data['data'][0]['paragraphs']\n",
    "     \n",
    "    data_rows = []\n",
    "    \n",
    "    for question in questions:\n",
    "        context = question['context']\n",
    "\n",
    "        for question_and_answers in question['qas']:\n",
    "            question = question_and_answers['question']\n",
    "            answers = question_and_answers['answers']\n",
    "\n",
    "            for answer in answers:\n",
    "                answer_text = answer['text']\n",
    "                answer_start = answer['answer_start']\n",
    "                answer_end = answer['answer_start'] + len(answer_text)\n",
    "                    \n",
    "                data_rows.append({\n",
    "                     \"question\" : question,\n",
    "                     \"context\"  : context,\n",
    "                     \"answer_text\" : answer_text,\n",
    "                     \"answer_start\" : answer_start,\n",
    "                     \"answer_end\" : answer_end\n",
    "                     })\n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ed2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_questions_and_answers(Path(\"BioASQ/BioASQ-train-factoid-4b.json\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97477a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('BioASQ/BioASQ-train-factoid-4b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-5b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-6b.json')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = sorted(list(Path(\"BioASQ/\").glob(\"BioASQ-train-*\")))\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adding all three training files into the dataframe </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "114f80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = []\n",
    "\n",
    "for path in paths:\n",
    "    df_new.append(extract_questions_and_answers(path))\n",
    "    \n",
    "df_bioasq = pd.concat(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f181918f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bioasq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will do some basic data analysis to feed into our model and look for any descepencies into our data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5938b111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12988, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bioasq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12988"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bioasq.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bioasq.question.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> we can see that our data have some duplicates in the question so we will drop the duplicate questions from our database </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bioasq = df_bioasq.drop_duplicates(subset = [\"context\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2582, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bioasq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8683b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bioasq.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b0ddc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bioasq.context.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Context looks fine </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "383b90c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question        What is the characteristic feature of the Dyke...\n",
       "context         Left hemisphere and male sex dominance of cere...\n",
       "answer_text                                  cerebral hemiatrophy\n",
       "answer_start                                                  130\n",
       "answer_end                                                    150\n",
       "Name: 240, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = df_bioasq.iloc[240]\n",
    "sample_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Initiating model name since we are going to fine tune t5-base pretrained model to train our question answering</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2cecc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing encoder and decoder from t5-base pretrained model on sample data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b27c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(sample_question[\"question\"],sample_question[\"context\"], max_length = 396, padding = \"max_length\", \n",
    "          truncation = \"only_second\", return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "114f5110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>',\n",
       " 'additional_special_tokens': ['<extra_id_0>',\n",
       "  '<extra_id_1>',\n",
       "  '<extra_id_2>',\n",
       "  '<extra_id_3>',\n",
       "  '<extra_id_4>',\n",
       "  '<extra_id_5>',\n",
       "  '<extra_id_6>',\n",
       "  '<extra_id_7>',\n",
       "  '<extra_id_8>',\n",
       "  '<extra_id_9>',\n",
       "  '<extra_id_10>',\n",
       "  '<extra_id_11>',\n",
       "  '<extra_id_12>',\n",
       "  '<extra_id_13>',\n",
       "  '<extra_id_14>',\n",
       "  '<extra_id_15>',\n",
       "  '<extra_id_16>',\n",
       "  '<extra_id_17>',\n",
       "  '<extra_id_18>',\n",
       "  '<extra_id_19>',\n",
       "  '<extra_id_20>',\n",
       "  '<extra_id_21>',\n",
       "  '<extra_id_22>',\n",
       "  '<extra_id_23>',\n",
       "  '<extra_id_24>',\n",
       "  '<extra_id_25>',\n",
       "  '<extra_id_26>',\n",
       "  '<extra_id_27>',\n",
       "  '<extra_id_28>',\n",
       "  '<extra_id_29>',\n",
       "  '<extra_id_30>',\n",
       "  '<extra_id_31>',\n",
       "  '<extra_id_32>',\n",
       "  '<extra_id_33>',\n",
       "  '<extra_id_34>',\n",
       "  '<extra_id_35>',\n",
       "  '<extra_id_36>',\n",
       "  '<extra_id_37>',\n",
       "  '<extra_id_38>',\n",
       "  '<extra_id_39>',\n",
       "  '<extra_id_40>',\n",
       "  '<extra_id_41>',\n",
       "  '<extra_id_42>',\n",
       "  '<extra_id_43>',\n",
       "  '<extra_id_44>',\n",
       "  '<extra_id_45>',\n",
       "  '<extra_id_46>',\n",
       "  '<extra_id_47>',\n",
       "  '<extra_id_48>',\n",
       "  '<extra_id_49>',\n",
       "  '<extra_id_50>',\n",
       "  '<extra_id_51>',\n",
       "  '<extra_id_52>',\n",
       "  '<extra_id_53>',\n",
       "  '<extra_id_54>',\n",
       "  '<extra_id_55>',\n",
       "  '<extra_id_56>',\n",
       "  '<extra_id_57>',\n",
       "  '<extra_id_58>',\n",
       "  '<extra_id_59>',\n",
       "  '<extra_id_60>',\n",
       "  '<extra_id_61>',\n",
       "  '<extra_id_62>',\n",
       "  '<extra_id_63>',\n",
       "  '<extra_id_64>',\n",
       "  '<extra_id_65>',\n",
       "  '<extra_id_66>',\n",
       "  '<extra_id_67>',\n",
       "  '<extra_id_68>',\n",
       "  '<extra_id_69>',\n",
       "  '<extra_id_70>',\n",
       "  '<extra_id_71>',\n",
       "  '<extra_id_72>',\n",
       "  '<extra_id_73>',\n",
       "  '<extra_id_74>',\n",
       "  '<extra_id_75>',\n",
       "  '<extra_id_76>',\n",
       "  '<extra_id_77>',\n",
       "  '<extra_id_78>',\n",
       "  '<extra_id_79>',\n",
       "  '<extra_id_80>',\n",
       "  '<extra_id_81>',\n",
       "  '<extra_id_82>',\n",
       "  '<extra_id_83>',\n",
       "  '<extra_id_84>',\n",
       "  '<extra_id_85>',\n",
       "  '<extra_id_86>',\n",
       "  '<extra_id_87>',\n",
       "  '<extra_id_88>',\n",
       "  '<extra_id_89>',\n",
       "  '<extra_id_90>',\n",
       "  '<extra_id_91>',\n",
       "  '<extra_id_92>',\n",
       "  '<extra_id_93>',\n",
       "  '<extra_id_94>',\n",
       "  '<extra_id_95>',\n",
       "  '<extra_id_96>',\n",
       "  '<extra_id_97>',\n",
       "  '<extra_id_98>',\n",
       "  '<extra_id_99>']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f7642fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e914e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the characteristic feature of the Dyke-Davidoff-Masson syndrome.</s> Left hemisphere and male sex dominance of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome). Although radiological findings of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome) are well known, there is no systematic study about the gender and the affected side in this syndrome. Brain images in 26 patients (mean aged 11) with cerebral hemiatrophy were retrospectively reviewed. Nineteen patients (73.5%) were male and seven patients (26.5%) were female. Left hemisphere involvement was seen in 18 patients (69.2%) and right hemisphere involvement was seen in eight patients (30.8%). We conclude that male gender and left side involvement are frequent in cerebral hemiatrophy disease.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We have to create necessary labels for the answers. We can extract answers according to questions </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85705f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_encoding = tokenizer(\n",
    "     sample_question['answer_text'],\n",
    "     max_length=32,\n",
    "     padding='max_length',\n",
    "     truncation=True,\n",
    "     return_attention_mask=True,\n",
    "     add_special_tokens=True,\n",
    "     return_tensors=\"pt\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31d54acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerebral hemiatrophy</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_encoding['input_ids'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c408d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = answer_encoding[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f50386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5edc7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels == 0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02d9bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Creating function to tokenize data using tokenization using t5 tokenizer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c8ca551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeData(Dataset):\n",
    "    \n",
    "    def __init__(self, data:pd.DataFrame, tokenizer:T5Tokenizer, source_max_token_len: int =369, target_max_token_len: int =32):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        \n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        source_encoding = tokenizer(data_row['question'], data_row['context'], max_length=self.source_max_token_len,\n",
    "                                        padding='max_length', truncation=\"only_second\", return_attention_mask=True,\n",
    "                                        add_special_tokens=True, return_tensors=\"pt\")\n",
    "        \n",
    "        target_encoding = tokenizer(data_row['answer_text'], max_length=self.target_max_token_len, padding='max_length',\n",
    "                                        truncation=True, return_attention_mask=True, add_special_tokens=True,\n",
    "                                        return_tensors=\"pt\")\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(question = data_row[\"question\"], context = data_row[\"context\"], answer_text = data_row[\"answer_text\"],\n",
    "                       input_ids = source_encoding[\"input_ids\"].flatten(), \n",
    "                       attention_mask = source_encoding[\"attention_mask\"].flatten(), labels = labels.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sample data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = TokenizeData(df_bioasq,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b5edb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the inheritance pattern of Li–Fraumeni syndrome?\n",
      "answers:  autosomal dominant\n",
      "input_ids:  tensor([  363,    19,     8, 28915,  3275,    13,  1414,   104,   371,  6340])\n",
      "labels:  tensor([ 1510, 10348,   138, 12613,     1,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "for data in sample_dataset:\n",
    "    print(\"question: \", data[\"question\"])\n",
    "    print(\"answers: \",data[\"answer_text\"])\n",
    "    print(\"input_ids: \", data[\"input_ids\"][:10])\n",
    "    print(\"labels: \", data[\"labels\"][:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Doing a train test split of 80/20 respecticely for our model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d094b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioasq_train_df, bioasq_val_df = train_test_split(df_bioasq, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51b90f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2065, 5)\n",
      "(517, 5)\n"
     ]
    }
   ],
   "source": [
    "print(bioasq_train_df.shape)\n",
    "print(bioasq_val_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a function to create data to feed into our model. We did padding and tokenization from this function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cb38dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateData(pl.LightningDataModule):\n",
    "    def __init__(self, train_df: pd.DataFrame, test_df: pd.DataFrame, tokenizer:T5Tokenizer, batch_size: int = 8,\n",
    "                    source_max_token_len: int = 396, target_max_token_len: int = 32):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "   \n",
    "    def setup(self):\n",
    "        \n",
    "        self.train_dataset = TokenizeData(self.train_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "        self.test_dataset = TokenizeData(self.test_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Setting up our data and model to start training. We will run total of 6 epocks with smaller batch of 4 because of the dataset available for training </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d23bc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 6\n",
    "\n",
    "data_module = CreateData(bioasq_train_df, bioasq_val_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> MODEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0c666ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52c131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "584e3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32128])\n"
     ]
    }
   ],
   "source": [
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE PYTORCH LIGHTNING MODULE\n",
    "\n",
    "<b> We are creating the function QAModel for using pytorch lightning module. Reference link - https://pytorch-lightning.readthedocs.io/en/latest/starter/lightning_lite.html to create the method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "094c531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "   \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \n",
    "        output = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return output.loss, output.logits\n",
    "   \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True, on_step=True)\n",
    "        return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n",
    "       \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True, on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=0.0001)\n",
    "        return optimizer      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27b747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Using pytorchlightning function callback to save the best model from our epochs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitk/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Checkpoint directory BioASQ_checkpoints exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=\"BioASQ_checkpoints\", filename=\"BioASQ-best-checkpoint\", save_top_k=1,\n",
    "                                        verbose=True, monitor=\"val_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Start training our model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dd64375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(checkpoint_callback=checkpoint_callback, max_epochs=NUM_EPOCHS, gpus=1, progress_bar_refresh_rate = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2bb54d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e888e8671e04eb297ae73b2ae7e9740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f650f049ff438d93e27bb36e1f05ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 516: val_loss reached 0.01468 (best 0.01468), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1033: val_loss reached 0.00967 (best 0.00967), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1550: val_loss reached 0.00202 (best 0.00202), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 2067: val_loss reached 0.00098 (best 0.00098), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 2584: val_loss reached 0.00041 (best 0.00041), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 3101: val_loss reached 0.00018 (best 0.00018), saving model to \"/data/user/ankitk/NLP/BioASQ_checkpoints/BioASQ-best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing and evaluating the object we just trained.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60dc839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca6077c0b88438f84045f236ad19499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0001760245067998767, 'test_loss_epoch': 0.2404516637325287}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.2404516637325287, 'test_loss': 0.0001760245067998767}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAModel(\n",
       "  (model): T5ForConditionalGeneration(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseReluDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0985684468f9487bbc072ba93902dc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0001973738835658878, 'test_loss_epoch': 0.11475042998790741}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.11475042998790741, 'test_loss': 0.0001973738835658878}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(ckpt_path = \"BioASQ_checkpoints/BioASQ-best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading the best saved model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "249132d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = QAModel.load_from_checkpoint(\"BioASQ_checkpoints/BioASQ-best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c64dc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Creating a function to generate answers on our validation set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "928ad149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding=tokenizer(question[\"question\"], question['context'], max_length = 396, padding=\"max_length\",\n",
    "                            truncation=\"only_second\", return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(input_ids=source_encoding[\"input_ids\"], attention_mask=source_encoding[\"attention_mask\"],\n",
    "                                                num_beams=1, max_length=80, repetition_penalty=2.5,\n",
    "                                                length_penalty = 1.0, early_stopping=True, use_cache=True)\n",
    "\n",
    "    preds = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "             for generated_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Manually checking a few samples from our dataset to evaluate how our model is performing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question         Which calcium channels does ethosuximide target?\n",
       "context         Inhibition of T-type calcium channels and hydr...\n",
       "answer_text                               T-type calcium channels\n",
       "answer_start                                                  459\n",
       "answer_end                                                    482\n",
       "Name: 1732, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = bioasq_val_df.iloc[20]\n",
    "sample_question  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-type calcium channels'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question[\"answer_text\"]  # Label Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-type calcium channels'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question)  # Predicted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = bioasq_val_df.iloc[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcription factor EB (TFEB)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcription factor EB (TFEB)'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING OUR MODEL USING F1 Score\n",
    "<b> Function to evaluate f1 score</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(prediction, ground_truth):\n",
    "    \"\"\"Calculates F1 score.\n",
    "    Args:\n",
    "        prediction: Predicted answer span (string).\n",
    "        ground_truth: True answer span (string).\n",
    "    Returns:\n",
    "        F1 score.\n",
    "    \"\"\"\n",
    "  \n",
    "    common = Counter(prediction) & Counter(ground_truth)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction)\n",
    "    recall = 1.0 * num_same / len(ground_truth)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_words = []\n",
    "ground_truth = []\n",
    "    \n",
    "for i in range(len(bioasq_val_df)) :\n",
    "    predicted_words.append(generate_answer(bioasq_val_df.iloc[i]))\n",
    "    ground_truth.append(bioasq_val_df.iloc[i]['answer_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBN1',\n",
       " 'Hyaluronidase',\n",
       " 'experimental autoimmune',\n",
       " 'LHCI',\n",
       " 'TYR',\n",
       " '7',\n",
       " 'tyrosinase',\n",
       " 'multiple myeloma',\n",
       " 'BCR-ABL',\n",
       " \"Alzheimer's disease\",\n",
       " 'spinal muscular atrophy',\n",
       " 'post-traumatic stress disorder',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'lamp2a',\n",
       " 'PD-L1',\n",
       " 'ataxin-3',\n",
       " 'SECIS',\n",
       " 'Cystic Fibro',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'posttraumatic stress disorder',\n",
       " 'T-type calcium channels',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'MRSA',\n",
       " 'H3K4',\n",
       " 'liver',\n",
       " 'repressor',\n",
       " 'BCR-ABL',\n",
       " 'Notch3 gene',\n",
       " 'SECIS',\n",
       " 'RET',\n",
       " 'tofacitinib',\n",
       " 'SLC9A6',\n",
       " 'RANKL',\n",
       " 'EGFR',\n",
       " 'riocitentan',\n",
       " 'lung',\n",
       " 'diabetes mellitus',\n",
       " 'Autosomal recessesive',\n",
       " 'selenoprotein P-like protein',\n",
       " 'Anorexia Athletica',\n",
       " 'JNK',\n",
       " 'ZEB2',\n",
       " 'medicarpin',\n",
       " 'AAUAAA',\n",
       " 'autosomal recessesive',\n",
       " 'medicarpin',\n",
       " 'MRSA',\n",
       " 'connective tissue',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'Retto syndrome',\n",
       " 'L-Dopa',\n",
       " 'poly(ADP-Ribose) polymerase',\n",
       " 'Xist',\n",
       " 'CaSR function is a G-protein coupled receptor',\n",
       " 'thyroid',\n",
       " 'multiple',\n",
       " 'malaria',\n",
       " 'X',\n",
       " 'There is a strong association between Narcolepsy and H1N1 vaccination',\n",
       " '7',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'ICDAVF',\n",
       " 'CD38',\n",
       " 'CaM Kinase II',\n",
       " 'Tofacitinib',\n",
       " 'transcription factor EB (TFEB)',\n",
       " 'X-linked dystonia',\n",
       " '15',\n",
       " 'psoriais',\n",
       " 'alpha-synuclein',\n",
       " 'RNA polymerase II',\n",
       " '55 S',\n",
       " 'BCR-ABL',\n",
       " 'heel pain',\n",
       " 'spleen',\n",
       " 'tardive dyskinesia',\n",
       " 'Dnmt1',\n",
       " 'NOTCH3 gene',\n",
       " 'Teriflunomide',\n",
       " 'Naloxone hydrochloride',\n",
       " 'positive',\n",
       " 'Cyclin D-cyclindependent kinase',\n",
       " 'PPI-1',\n",
       " 'dADAR',\n",
       " 'proteasome',\n",
       " 'SET domain',\n",
       " 'frataxin',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'RANKL',\n",
       " 'malaria',\n",
       " 'multiple',\n",
       " 'RNA polymerase II',\n",
       " 'NF1',\n",
       " 'Coilin',\n",
       " 'Calsequestrin',\n",
       " 'fungi',\n",
       " 'malaria',\n",
       " 'BCR-ABL',\n",
       " 'L-dopa',\n",
       " 'meningioma',\n",
       " 'FBN1',\n",
       " 'X-linked amyotrophic latent dementia',\n",
       " 'campomelic dysplasia',\n",
       " 'heel pain',\n",
       " 'EGFR',\n",
       " 'motor neurons',\n",
       " 'autosomal dominant',\n",
       " 'connective tissue',\n",
       " '1,4-benzothiazepine',\n",
       " 'RADAR',\n",
       " 'type 2 diabetes',\n",
       " 'NCX',\n",
       " 'fungi',\n",
       " 'Alpha-synuclein',\n",
       " 'PD-L1',\n",
       " 'nestin',\n",
       " 'flumazenil',\n",
       " 'experimental autoimmune',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'SAM',\n",
       " 'Trcp',\n",
       " 'interferon signature',\n",
       " \"Alzheimer's disease\",\n",
       " 'XK',\n",
       " 'chromosome IV',\n",
       " 'obesity',\n",
       " 'heel pain',\n",
       " 'Xa',\n",
       " 'alpha-synuclein',\n",
       " 'calcitonin gene-related protein',\n",
       " 'BCR-ABL',\n",
       " 'H3K36me3)',\n",
       " 'thyroid',\n",
       " 'X-linked dystonia–parkinsonism',\n",
       " 'Bcr-Abl',\n",
       " 'thyroid',\n",
       " 'three',\n",
       " 'spleen',\n",
       " 'Telomerase',\n",
       " 'Bcr-Abl',\n",
       " 'Fanconi anemia (FA) pathway',\n",
       " 'Nox1',\n",
       " 'orally',\n",
       " '1,4-benzothiazepine',\n",
       " 'malaria',\n",
       " 'autosomal dominant',\n",
       " 'diabetes mellitus',\n",
       " 'L-DOPA',\n",
       " 'proprotein convertase subtilisin/kexin type 9',\n",
       " 'ALS',\n",
       " 'ibrutina',\n",
       " 'the human homologue of Mdm2 (Hamm2)',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'CD38',\n",
       " 'NCX',\n",
       " 'FBN1',\n",
       " 'Viroids',\n",
       " 'fewer than 100',\n",
       " 'iron',\n",
       " 'LEKTI',\n",
       " 'Rac1',\n",
       " 'Ataxin-3',\n",
       " 'JNK',\n",
       " 'Coilin',\n",
       " 'Bcr-Abl',\n",
       " 'MDM two binding protein (MTBP)',\n",
       " 'development',\n",
       " 'Xa',\n",
       " 'MRSA',\n",
       " 'p16Ink4',\n",
       " 'respiratory distress syndrome',\n",
       " 'orexin',\n",
       " 'TFIIB',\n",
       " 'acetylated',\n",
       " 'ZFHX1B',\n",
       " 'multiple myeloma',\n",
       " 'Liver',\n",
       " 'Bazex syndrome',\n",
       " 'ribosomal protein genes',\n",
       " 'transcription factor EB (TFEB)',\n",
       " 'Light-harvesting pigment–protein complex of Photosystem II',\n",
       " 'MRSA',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'meningioma',\n",
       " 'SERCA',\n",
       " 'AdoMet',\n",
       " 'p53',\n",
       " 'zfhx1b',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'BCR-ABL',\n",
       " 'Chediak-Higashi syndrome',\n",
       " 'p16Ink4',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'collagen',\n",
       " 'Sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'S-adenosylmethionine',\n",
       " 'BCR-ABL',\n",
       " 'nerve growth factor',\n",
       " 'Restless legs syndrome',\n",
       " 'TFIIB',\n",
       " 'proteasome',\n",
       " 'MRSA',\n",
       " 'p53',\n",
       " 'Dnmt1',\n",
       " 'NCX',\n",
       " 'MRSA',\n",
       " 'mTOR',\n",
       " 'X',\n",
       " 'proteasome',\n",
       " 'diabetes mellitus',\n",
       " 'dermatitis herpetiformis',\n",
       " 'A-to–I',\n",
       " 'MRSA',\n",
       " '1,4-benzothiazepine',\n",
       " 'Tofacitinib',\n",
       " 'connective tissue',\n",
       " 'connective tissue',\n",
       " 'Medulloblastoma',\n",
       " 'three',\n",
       " 'factor Xa',\n",
       " 'XK',\n",
       " 'BCR-ABL',\n",
       " 'thyroid',\n",
       " 'post-traumatic stress disorder',\n",
       " 'H3K4',\n",
       " 'coilin',\n",
       " 'FBN1',\n",
       " 'glucocerebrosidasa',\n",
       " 'DNMT1',\n",
       " '55 S',\n",
       " 'mitochondrial fission',\n",
       " 'non-synonymous',\n",
       " 'Xist',\n",
       " 'Ataxin-3',\n",
       " 'NSD1 gene',\n",
       " 'BCR-ABL',\n",
       " 'luminal side of the endoplasmic reticulum',\n",
       " 'H3K36me3)',\n",
       " 'H3K36 trimethylation',\n",
       " 'Sushi.R',\n",
       " 'FBN1',\n",
       " 'JNK',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'MRSA',\n",
       " 'SWR1',\n",
       " 'Na(+) exchanger',\n",
       " 'mammalian target of rap',\n",
       " 'Nox1',\n",
       " 'centrosome',\n",
       " 'motor neurons',\n",
       " '7',\n",
       " 'Rotor syndrome',\n",
       " 'BCR-ABL',\n",
       " 'NF1',\n",
       " 'malaria',\n",
       " 'ibrutinab',\n",
       " 'repressor',\n",
       " 'Xa',\n",
       " 'myoclonic astatic epilepsy',\n",
       " 'RANKL',\n",
       " 'castration-resistant prostate cancer',\n",
       " 'beta glucocerebrosidas',\n",
       " 'tyrosinase',\n",
       " 'p16INK4',\n",
       " 'FBN1',\n",
       " 'Medicarpin',\n",
       " 'lumbosacra',\n",
       " \"Gaucher's disease type 1\",\n",
       " 'p53',\n",
       " 'glucocerebrosidas',\n",
       " 'Nox1',\n",
       " 'mitochondrial fission',\n",
       " 'interleukin-17A',\n",
       " 'Restless legs syndrome',\n",
       " 'serine 129',\n",
       " '7',\n",
       " 'interferon signature',\n",
       " 'beta-Trcp',\n",
       " '7',\n",
       " 'hypertension',\n",
       " '1,4-benzothiazepine',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'MITF',\n",
       " 'mitochondrial fission',\n",
       " \"Crohn's disease has a bimodal age distribution of disease-onset diagnosis\",\n",
       " 'connective tissue',\n",
       " 'centromeres',\n",
       " 'cyclophilin',\n",
       " 'L-Dopa',\n",
       " 'galactocerebrosidasis',\n",
       " 'tuberculosis',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'Flumazenil',\n",
       " 'CDK4/6',\n",
       " '1:5000',\n",
       " 'connective tissue',\n",
       " 'NF1',\n",
       " 'Calsequestrin',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'X',\n",
       " 'epidural blood patch',\n",
       " 'Swr1',\n",
       " 'viroids',\n",
       " 'Tofacitinib',\n",
       " 'ribosomal protein genes',\n",
       " 'chaperone-mediated autophagy (CMA)',\n",
       " 'CD38',\n",
       " 'focal cortical dysplasia',\n",
       " 'catechol-O methyltransferase',\n",
       " 'growth hormone',\n",
       " 'SWR1',\n",
       " 'Clostridium botulinum',\n",
       " 'RANKL',\n",
       " 'frataxin',\n",
       " 'RET',\n",
       " 'mitotic arrest',\n",
       " 'Pse-in One',\n",
       " 'GKT136901',\n",
       " 'ultrasound',\n",
       " 'castration-resistant prostate cancer',\n",
       " '7',\n",
       " 'hypertrophic cardiomyopathy',\n",
       " 'BCR-ABL',\n",
       " 'aging research',\n",
       " 'Xa',\n",
       " 'tyrosinase',\n",
       " 'frataxin',\n",
       " 'malaria',\n",
       " 'HIV',\n",
       " 'SECIS',\n",
       " 'increased olfactory',\n",
       " '7',\n",
       " 'NOTCH3 gene',\n",
       " 'tyrosinase',\n",
       " 'Thyroid transcription factor 1',\n",
       " 'major depressive disorder',\n",
       " 'PU.1',\n",
       " 'JNK',\n",
       " 'Dnmt1',\n",
       " 'p53',\n",
       " 'Bazex syndrome',\n",
       " 'CO2',\n",
       " 'craniosynostosesis',\n",
       " 'PARP',\n",
       " 'Dnmt1',\n",
       " 'glucocerebrosidas',\n",
       " 'teriflunomide',\n",
       " 'Inhibitor 1',\n",
       " 'CYP17A1',\n",
       " 'programmed death-ligand 1',\n",
       " 'antiparallel',\n",
       " 'Thyroid',\n",
       " 'alpha-synuclein',\n",
       " 'polycystic kidney disease (PKD)',\n",
       " 'NSD1 gene',\n",
       " '15',\n",
       " 'calcineurine',\n",
       " 'HEXA',\n",
       " 'CDK4/6',\n",
       " 'Aryl hydrocarbon receptor interacting protein',\n",
       " 'Fungi',\n",
       " 'FSHD',\n",
       " 'serine 129',\n",
       " 'selenoprotein P',\n",
       " 'diabetes mellitus',\n",
       " 'atrial fibrillation and flutter',\n",
       " 'FBN1',\n",
       " 'thyroid',\n",
       " 'epidural blood patch',\n",
       " 'coilin',\n",
       " 'NF1',\n",
       " 'X',\n",
       " '',\n",
       " 'ribosomal protein genes',\n",
       " 'repressor',\n",
       " '5-aminolevulinic acid',\n",
       " 'ALS',\n",
       " 'repressor',\n",
       " 'ZFHX1B',\n",
       " 'repressor',\n",
       " '7',\n",
       " 'calcitonin gene-related protein',\n",
       " 'thyroid',\n",
       " 'overactive bladder syndrome',\n",
       " 'lectin complement pathway',\n",
       " 'XK',\n",
       " 'Nasuia deltocephalinicola',\n",
       " 'catechol-O methyltransferase',\n",
       " 'factor Xa',\n",
       " 'cerebral hemiatrophy',\n",
       " 'growth hormone',\n",
       " 'interleukin-5',\n",
       " '2014',\n",
       " 'p53',\n",
       " 'NSD1 gene',\n",
       " 'orally',\n",
       " 'EGFR',\n",
       " 'ultrasound',\n",
       " 'SET domain',\n",
       " 'Stroke',\n",
       " 'epidermal growth factor receptor (EGFR) gene',\n",
       " 'autosomal dominant',\n",
       " 'repressor',\n",
       " 'thyroid',\n",
       " \"Alzheimer's disease\",\n",
       " 'x-linked dystonia–parkinsonism',\n",
       " 'type 2 diabetes mellitus',\n",
       " 'BCR-ABL',\n",
       " 'calcitonin gene-related protein',\n",
       " 'SGLT2',\n",
       " 'Keratoconus',\n",
       " 'glucocerebrosidasa',\n",
       " '-Synuclein',\n",
       " 'BCR-ABL',\n",
       " 'castration-resistant prostate cancer',\n",
       " 'nuclear',\n",
       " 'Lyst gene',\n",
       " 'l-DOPA',\n",
       " 'thyroid',\n",
       " 'BCR-ABL',\n",
       " 'dermatitis herpetiformis',\n",
       " 'Gaucher disease',\n",
       " 'CDK4/6',\n",
       " 'posttraumatic stress disorder',\n",
       " 'mTOR',\n",
       " 'all-alpha helical fold',\n",
       " 'NSD1 gene',\n",
       " 'glucocerebrosidas',\n",
       " 'lung',\n",
       " 'miR-138',\n",
       " 'connective tissue',\n",
       " '7',\n",
       " 'ultrasound',\n",
       " 'Rotor syndrome',\n",
       " 'Centrosome',\n",
       " 'DNMT1',\n",
       " 'IL-1',\n",
       " 'factor Xa',\n",
       " 'Arg886Trp',\n",
       " 'Ebola virus disease',\n",
       " 'FancD2 monoubiquitination',\n",
       " 'RNA polymerase II',\n",
       " 'Medicarpin',\n",
       " 'pulmonary arterial hypertension',\n",
       " 'BCR-ABL',\n",
       " 'autosomal dominant',\n",
       " 'galactocerebrosidasy',\n",
       " 'tofacitinib',\n",
       " 'multiple myeloma',\n",
       " 'BCR-ABL',\n",
       " 'tyrosinase',\n",
       " 'connective tissue',\n",
       " 'recession',\n",
       " 'NF1',\n",
       " 'BCR-ABL',\n",
       " 'dermatitis herpetiformis',\n",
       " 'posttraumatic stress disorder',\n",
       " 'ADAR',\n",
       " 'catechol-O methyltransferase',\n",
       " 'XIST',\n",
       " 'cerebral hemiatrophy',\n",
       " 'HEXA',\n",
       " 'malaria',\n",
       " 'bcr-abl',\n",
       " 'orally',\n",
       " 'natural inhibitor of IL-18',\n",
       " 'interleukin-17A',\n",
       " '5-HT2A',\n",
       " 'SET domain',\n",
       " 'aryl hydrocarbon receptor',\n",
       " 'MRSA',\n",
       " 'SGLT2',\n",
       " 'Plasmodium species',\n",
       " 'heterodimeric Rag GTPases',\n",
       " 'Dnmt1',\n",
       " 'Francisella tularensis',\n",
       " 'apoE4 isoform',\n",
       " 'HEXA',\n",
       " 'craniosynostoses',\n",
       " 'calcitonin gene-related',\n",
       " 'Human chorionic gonadotropin',\n",
       " 'heel pain',\n",
       " 'BCR-ABL',\n",
       " 'p53',\n",
       " 'viroids',\n",
       " 'SECIS',\n",
       " 'lung',\n",
       " 'proprotein convertase subtilisin/kexin type 9',\n",
       " 'SECIS',\n",
       " 'NF1',\n",
       " 'OikoBase',\n",
       " 'IgG4',\n",
       " 'Pthirus pubis',\n",
       " 'beta-TrCP',\n",
       " 'insulin',\n",
       " 'Xa',\n",
       " 'the transcribed strand',\n",
       " 'TFIIB',\n",
       " 'HIV',\n",
       " 'The RESID Database of Protein Modifications is an extensive collection',\n",
       " 'SECIS',\n",
       " 'Clostridium botulinum',\n",
       " 'ackea fruit',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'Bcr-Abl',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'development',\n",
       " 'centromeres',\n",
       " 'alpha-synuclein',\n",
       " 'NF1',\n",
       " 'Tofacitinib',\n",
       " 'SWR1',\n",
       " 'nuclear',\n",
       " 'FBN1',\n",
       " 'DNMT1',\n",
       " 'XK']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBN1',\n",
       " 'GKT136901',\n",
       " 'experimental autoimmune encephalomyelitis (EAE)',\n",
       " 'LHCII',\n",
       " 'TYR',\n",
       " '7',\n",
       " 'tyrosinase',\n",
       " 'multiple myeloma',\n",
       " 'BCR-ABL',\n",
       " \"Alzheimer's disease\",\n",
       " 'Spinal Muscular Atrophy',\n",
       " 'post-traumatic stress disorder',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'lamp2a',\n",
       " 'PD-L1',\n",
       " 'ataxin-3',\n",
       " 'SECIS',\n",
       " 'DeltaF508',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'PTSD',\n",
       " 'T-type calcium channels',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'MRSA',\n",
       " 'H3K4',\n",
       " 'liver',\n",
       " 'repressor',\n",
       " 'BCR-ABL',\n",
       " 'Notch3 gene',\n",
       " 'SECIS',\n",
       " 'RET',\n",
       " 'tofacitinib',\n",
       " 'SLC9A6',\n",
       " 'RANKL',\n",
       " 'EGFR',\n",
       " 'riociguat',\n",
       " 'lung',\n",
       " 'diabetes mellitus',\n",
       " 'autosomal recessive',\n",
       " 'selenoprotein P',\n",
       " 'Anorexia Athletica',\n",
       " 'JNK',\n",
       " 'ZEB2',\n",
       " 'medicarpin',\n",
       " 'AAUAAA',\n",
       " 'autosomal recessive',\n",
       " 'medicarpin',\n",
       " 'MRSA',\n",
       " 'connective tissue',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'Rett syndrome',\n",
       " 'L-Dopa',\n",
       " 'poly(ADP-Ribose) polymerase',\n",
       " 'Xist',\n",
       " 'The calcium-sensing receptor (CaSR) is a G-protein-coupled receptor that plays an essential role in maintaining calcium homeostasis.',\n",
       " 'thyroid',\n",
       " 'multiple',\n",
       " 'malaria',\n",
       " 'X',\n",
       " 'The proposed mechanism for postvaccination narcolepsy is one in which an environmental trigger causes or enhances an antibody-mediated autoimmune response in patients with a preexisting genetic susceptibility.',\n",
       " '7',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'cranial dural arteriovenous fistula',\n",
       " 'CD38',\n",
       " 'CaM Kinase II',\n",
       " 'Tofacitinib',\n",
       " 'transcription factor EB (TFEB)',\n",
       " 'X-linked dystonia-parkinsonism',\n",
       " '15',\n",
       " 'psoriasis',\n",
       " 'Alpha-synuclein',\n",
       " 'RNA polymerase II',\n",
       " '55 S',\n",
       " 'BCR-ABL',\n",
       " 'heel pain',\n",
       " 'spleen tyrosine kinase',\n",
       " 'Valbenazine granted breakthrough drug status for treating tardive dyskinesia.',\n",
       " 'Dnmt1',\n",
       " 'NOTCH3 gene',\n",
       " 'teriflunomide',\n",
       " 'Naloxone',\n",
       " 'positive',\n",
       " 'CDK4/6',\n",
       " 'PPI-1',\n",
       " 'ADAR',\n",
       " 'proteasome',\n",
       " 'SET domain',\n",
       " 'frataxin',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'RANKL',\n",
       " 'malaria',\n",
       " 'multiple',\n",
       " 'RNA polymerase II',\n",
       " 'NF1',\n",
       " 'Coilin',\n",
       " 'Calsequestrin',\n",
       " 'fungi',\n",
       " 'malaria',\n",
       " 'BCR-ABL',\n",
       " 'L-dopa',\n",
       " 'meningioma',\n",
       " 'FBN1',\n",
       " 'ALS',\n",
       " 'Autosomal XX sex reversal',\n",
       " 'heel pain',\n",
       " 'EGFR',\n",
       " 'motor neurons',\n",
       " 'autosomal dominant',\n",
       " 'connective tissue',\n",
       " '1,4-benzothiazepine',\n",
       " 'RADAR',\n",
       " 'type 2 diabetes',\n",
       " 'NCX',\n",
       " 'fungi',\n",
       " 'Alpha-synuclein',\n",
       " 'PD-L1',\n",
       " 'nestin',\n",
       " 'flumazenil',\n",
       " 'experimental autoimmune encephalomyelitis (EAE)',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'SAM',\n",
       " 'βTrcp',\n",
       " 'interferon signature',\n",
       " \"Alzheimer's disease\",\n",
       " 'XK',\n",
       " 'chromosome XII',\n",
       " 'obesity',\n",
       " 'heel pain',\n",
       " 'Xa',\n",
       " 'alpha-synuclein',\n",
       " 'calcitonin gene-related peptide',\n",
       " 'BCR-ABL',\n",
       " 'H3K36me3',\n",
       " 'thyroid',\n",
       " 'X-linked dystonia-parkinsonism',\n",
       " 'Bcr-Abl',\n",
       " 'thyroid',\n",
       " 'three',\n",
       " 'spleen tyrosine kinase',\n",
       " 'Telomerase',\n",
       " 'Bcr-Abl',\n",
       " 'PARP',\n",
       " 'Nox1',\n",
       " 'orally',\n",
       " '1,4-benzothiazepine',\n",
       " 'malaria',\n",
       " 'autosomal dominant',\n",
       " 'diabetes mellitus',\n",
       " 'L-DOPA',\n",
       " 'proprotein convertase subtilisin/kexin type 9',\n",
       " 'ALS',\n",
       " 'ibrutinib',\n",
       " 'the human homologue of Mdm2 (Hdm2)',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'CD38',\n",
       " 'NCX',\n",
       " 'FBN1',\n",
       " 'Viroids',\n",
       " ' fewer than 100',\n",
       " 'iron',\n",
       " 'LEKTI',\n",
       " 'Rac1',\n",
       " 'Ataxin-3',\n",
       " 'JNK',\n",
       " 'Coilin',\n",
       " 'Bcr-Abl',\n",
       " 'MDM two binding protein (MTBP)',\n",
       " 'development',\n",
       " 'xa',\n",
       " 'MRSA',\n",
       " 'p16Ink4',\n",
       " 'respiratory distress syndrome',\n",
       " 'orexin',\n",
       " 'TFIIB',\n",
       " 'acetylated lysines',\n",
       " 'ZFHX1B',\n",
       " 'multiple myeloma',\n",
       " 'Liver',\n",
       " 'Bazex syndrome',\n",
       " 'ribosomal protein genes',\n",
       " 'transcription factor EB (TFEB)',\n",
       " 'Light-harvesting pigment-protein complex of Photosystem II',\n",
       " 'MRSA',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'meningioma',\n",
       " 'SERCA',\n",
       " 'AdoMet',\n",
       " 'p53',\n",
       " 'zfhx1b',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'BCR-ABL',\n",
       " 'Chediak-Higashi syndrome',\n",
       " 'p16Ink4',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'collagen',\n",
       " 'Sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'S-adenosylmethionine',\n",
       " 'BCR-ABL',\n",
       " 'nerve growth factor',\n",
       " 'Restless legs syndrome',\n",
       " 'TFIIB',\n",
       " 'proteasome',\n",
       " 'MRSA',\n",
       " 'p53',\n",
       " 'Dnmt1',\n",
       " 'NCX',\n",
       " 'MRSA',\n",
       " 'mTOR',\n",
       " 'X',\n",
       " 'proteasome',\n",
       " 'diabetes mellitus',\n",
       " 'dermatitis herpetiformis',\n",
       " 'A-to-I',\n",
       " 'MRSA',\n",
       " '1,4-benzothiazepine',\n",
       " 'Tofacitinib',\n",
       " 'connective tissue',\n",
       " 'connective tissue',\n",
       " 'Medulloblastoma',\n",
       " 'three',\n",
       " 'factor Xa',\n",
       " 'XK',\n",
       " 'BCR-ABL',\n",
       " 'thyroid',\n",
       " 'post-traumatic stress disorder',\n",
       " 'H3K4',\n",
       " 'coilin',\n",
       " 'FBN1',\n",
       " 'glucocerebrosidase',\n",
       " 'DNMT1',\n",
       " '55 S',\n",
       " 'mitochondrial fission',\n",
       " 'non-synonymous',\n",
       " 'Xist',\n",
       " 'Ataxin-3',\n",
       " 'NSD1 gene',\n",
       " 'BCR-ABL',\n",
       " 'luminal side of the endoplasmic reticulum',\n",
       " 'H3K36me3',\n",
       " 'H3K36 trimethylation',\n",
       " 'Sushi.R',\n",
       " 'FBN1',\n",
       " 'JNK',\n",
       " 'NEDD8-activating enzyme',\n",
       " 'MRSA',\n",
       " 'SWR1',\n",
       " 'Na(+)/Ca(2+) exchanger',\n",
       " 'mammalian target of rapamycin',\n",
       " 'Nox1',\n",
       " 'centrosome',\n",
       " 'motor neurons',\n",
       " '7',\n",
       " 'Rotor syndrome',\n",
       " 'BCR-ABL',\n",
       " 'NF1',\n",
       " 'malaria',\n",
       " 'ibrutinib',\n",
       " 'repressor',\n",
       " 'Xa',\n",
       " 'myoclonic astatic epilepsy',\n",
       " 'RANKL',\n",
       " 'castration-resistant prostate cancer',\n",
       " 'beta glucocerebrosidase',\n",
       " 'tyrosinase',\n",
       " 'p16INK4',\n",
       " 'FBN1',\n",
       " 'Medicarpin',\n",
       " 'lumbosacral',\n",
       " \"Gaucher's disease type 1\",\n",
       " 'p53',\n",
       " 'glucocerebrosidase',\n",
       " 'Nox1',\n",
       " 'mitochondrial fission',\n",
       " 'interleukin-17A',\n",
       " 'Restless legs syndrome',\n",
       " 'serine 129',\n",
       " '7',\n",
       " 'interferon signature',\n",
       " 'beta-Trcp',\n",
       " '7',\n",
       " 'hypertension',\n",
       " '1,4-benzothiazepine',\n",
       " 'sudden unexpected death in epilepsy (SUDEP)',\n",
       " 'MITF',\n",
       " 'mitochondrial fission',\n",
       " \"Crohn's disease has a bimodal age distribution of disease onset diagnosis. The peaks (20 and 50 years) may represent different phenotypes or different genetic and/or environmental influences between younger- and older-onset individuals.\",\n",
       " 'connective tissue',\n",
       " 'centromeres',\n",
       " 'cyclophilin',\n",
       " 'L-Dopa',\n",
       " 'galactocerebrosidase',\n",
       " 'tuberculosis',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'Flumazenil',\n",
       " 'CDK4/6',\n",
       " '1:5000',\n",
       " 'connective tissue',\n",
       " 'NF1',\n",
       " 'Calsequestrin',\n",
       " 'Hypertrophic cardiomyopathy',\n",
       " 'X',\n",
       " 'epidural blood patch',\n",
       " 'Swr1',\n",
       " 'viroids',\n",
       " 'Tofacitinib',\n",
       " 'ribosomal protein genes',\n",
       " 'chaperone-mediated autophagy (CMA)',\n",
       " 'CD38',\n",
       " 'focal cortical dysplasia',\n",
       " 'catechol-O-methyltransferase',\n",
       " 'growth hormone',\n",
       " 'SWR1',\n",
       " 'Clostridium botulinum',\n",
       " 'RANKL',\n",
       " 'frataxin',\n",
       " 'RET',\n",
       " 'mitotic arrest',\n",
       " 'Pse-in-One',\n",
       " 'GKT136901',\n",
       " 'ultrasound',\n",
       " 'castration-resistant prostate cancer',\n",
       " '7',\n",
       " 'hypertrophic cardiomyopathy',\n",
       " 'BCR-ABL',\n",
       " 'aging research',\n",
       " 'Xa',\n",
       " 'tyrosinase',\n",
       " 'frataxin',\n",
       " 'malaria',\n",
       " 'HIV',\n",
       " 'SECIS',\n",
       " 'increased olfactory acuity',\n",
       " '7',\n",
       " 'NOTCH3 gene',\n",
       " 'tyrosinase',\n",
       " 'Thyroid transcription factor 1',\n",
       " 'PTSD',\n",
       " 'PU.1',\n",
       " 'JNK',\n",
       " 'Dnmt1',\n",
       " 'or ',\n",
       " 'Bazex syndrome',\n",
       " 'CO2',\n",
       " 'craniosynostosis',\n",
       " 'PARP',\n",
       " 'Dnmt1',\n",
       " 'glucocerebrosidase',\n",
       " 'teriflunomide',\n",
       " 'Inhibitor 1',\n",
       " 'CYP17A1',\n",
       " 'programmed death-ligand 1',\n",
       " 'antiparallel',\n",
       " 'Thyroid',\n",
       " 'alpha-synuclein',\n",
       " 'polycystic kidney disease (PKD)',\n",
       " 'NSD1 gene',\n",
       " '15',\n",
       " 'calcineurin',\n",
       " 'HEXA',\n",
       " 'CDK4/6',\n",
       " 'Aryl hydrocarbon receptor interacting protein',\n",
       " 'Fungi',\n",
       " 'FSHD',\n",
       " 'serine 129',\n",
       " 'selenoprotein P',\n",
       " 'diabetes mellitus',\n",
       " 'atrial fibrillation and flutter',\n",
       " 'FBN1',\n",
       " 'thyroid',\n",
       " 'epidural blood patch',\n",
       " 'coilin',\n",
       " 'NF1',\n",
       " 'X',\n",
       " '',\n",
       " 'ribosomal protein genes',\n",
       " 'repressor',\n",
       " '5-aminolevulinic acid',\n",
       " 'ALS',\n",
       " 'repressor',\n",
       " 'ZFHX1B',\n",
       " 'repressor',\n",
       " '7',\n",
       " 'calcitonin gene-related peptide',\n",
       " 'thyroid',\n",
       " 'overactive bladder syndrome',\n",
       " 'lectin complement pathway',\n",
       " 'XK',\n",
       " 'Nasuia deltocephalinicola',\n",
       " 'catechol-O-methyltransferase',\n",
       " 'factor Xa',\n",
       " 'cerebral hemiatrophy',\n",
       " 'growth hormone',\n",
       " 'interleukin-5',\n",
       " '2014',\n",
       " 'p53',\n",
       " 'NSD1 gene',\n",
       " 'orally',\n",
       " 'EGFR',\n",
       " 'ultrasound',\n",
       " 'SET domain',\n",
       " 'stroke',\n",
       " 'epidermal growth factor receptor (EGFR) gene',\n",
       " 'autosomal dominant',\n",
       " 'repressor',\n",
       " 'thyroid',\n",
       " \"Alzheimer's disease\",\n",
       " 'x-linked dystonia-parkinsonism',\n",
       " 'type 2 diabetes mellitus',\n",
       " 'BCR-ABL',\n",
       " 'calcitonin gene-related peptide',\n",
       " 'SGLT2',\n",
       " 'Keratoconus',\n",
       " 'glucocerebrosidase',\n",
       " 'α-Synuclein',\n",
       " 'BCR-ABL',\n",
       " 'castration-resistant prostate cancer',\n",
       " ' nuclear',\n",
       " 'Lyst gene',\n",
       " 'l-DOPA',\n",
       " 'thyroid',\n",
       " 'BCR-ABL',\n",
       " 'dermatitis herpetiformis',\n",
       " 'Gaucher disease',\n",
       " 'CDK4/6',\n",
       " 'PTSD',\n",
       " 'mTOR',\n",
       " 'all-alpha-helical fold',\n",
       " 'NSD1 gene',\n",
       " 'glucocerebrosidase',\n",
       " 'lung',\n",
       " 'miR-138',\n",
       " 'connective tissue',\n",
       " '7',\n",
       " 'ultrasound',\n",
       " 'Rotor syndrome',\n",
       " 'Centrosome',\n",
       " 'DNMT1',\n",
       " 'IL-1β',\n",
       " 'factor Xa',\n",
       " 'RET',\n",
       " 'Ebola virus disease',\n",
       " 'FancD2 monoubiquitination',\n",
       " 'RNA polymerase II',\n",
       " 'Medicarpin',\n",
       " 'pulmonary arterial hypertension',\n",
       " 'BCR-ABL',\n",
       " 'autosomal dominant',\n",
       " 'galactocerebrosidase',\n",
       " 'tofacitinib',\n",
       " 'multiple myeloma',\n",
       " 'BCR-ABL',\n",
       " 'tyrosinase',\n",
       " 'connective tissue',\n",
       " 'recessive hypolipidemia',\n",
       " 'NF1',\n",
       " 'BCR-ABL',\n",
       " 'Dermatitis herpetiformis',\n",
       " 'PTSD',\n",
       " 'ADAR',\n",
       " 'catechol-O-methyltransferase',\n",
       " 'XIST',\n",
       " 'cerebral hemiatrophy',\n",
       " 'HEXA',\n",
       " 'malaria',\n",
       " 'bcr-abl',\n",
       " 'orally',\n",
       " 'IL-18 binding protein (IL-18BP) is a natural inhibitor of IL-18. The balance between IL-18 and IL-18BP has an important role in the inflammatory setting.',\n",
       " 'interleukin-17A',\n",
       " '5-HT2A',\n",
       " 'SET domain',\n",
       " 'aryl hydrocarbon receptor interacting protein',\n",
       " 'MRSA',\n",
       " 'SGLT2',\n",
       " 'Plasmodium species',\n",
       " 'heterodimeric Rag GTPases',\n",
       " 'Dnmt1',\n",
       " 'Francisella tularensis',\n",
       " 'apoE4 isoform',\n",
       " 'HEXA',\n",
       " 'craniosynostosis',\n",
       " 'calcitonin gene-related peptide',\n",
       " 'hCG',\n",
       " 'heel pain',\n",
       " 'BCR-ABL',\n",
       " 'p53',\n",
       " 'viroids',\n",
       " 'SECIS',\n",
       " 'lung',\n",
       " 'proprotein convertase subtilisin/kexin type 9',\n",
       " 'SECIS',\n",
       " 'NF1',\n",
       " 'OikoBase',\n",
       " 'IgG4',\n",
       " 'Pthirus pubis',\n",
       " 'beta-TrCP',\n",
       " 'insulin',\n",
       " 'Xa',\n",
       " 'the transcribed strand',\n",
       " 'TFIIB',\n",
       " 'HIV',\n",
       " 'The RESID Database of Protein Modifications is a comprehensive collection of annotations and structures for protein modifications and cross-links including pre-, co-, and post-translational modifications',\n",
       " 'SECIS',\n",
       " 'Clostridium botulinum',\n",
       " 'ackee fruit',\n",
       " 'SUMO-conjugating enzyme',\n",
       " 'Bcr-Abl',\n",
       " 'fibroblast growth factor receptor 3 (FGFR3)',\n",
       " 'development',\n",
       " 'centromeres',\n",
       " 'alpha-synuclein',\n",
       " 'NF1',\n",
       " 'Tofacitinib',\n",
       " 'SWR1',\n",
       " ' nuclear',\n",
       " 'FBN1',\n",
       " 'DNMT1',\n",
       " 'XK']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Converting answers to strings to evaluate </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predicted_words = \",\".join(predicted_words)\n",
    "eval_ground_truth = \",\".join(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Checking our model's F1 score</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of our model ->  95.3475863923625\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score of our model -> \",100*f1_score(eval_predicted_words, eval_ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>SQUAD 2 DATASET</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will create data similarly for SqUAD2.0 dataset and feed it into the same model we trained for BioASQ dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! mkdir squad\n",
    "#! wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -O squad/train-v2.0.json\n",
    "#! wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json -O squad/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"squad/train-v2.0.json\").open() as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'data'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['data'][0]['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'question': 'When did Beyonce start becoming popular?',\n",
       "   'id': '56be85543aeaaa14008c9063',\n",
       "   'answers': [{'text': 'in the late 1990s', 'answer_start': 269}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "   'id': '56be85543aeaaa14008c9065',\n",
       "   'answers': [{'text': 'singing and dancing', 'answer_start': 207}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\",\n",
       "   'id': '56be85543aeaaa14008c9066',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what city and state did Beyonce  grow up? ',\n",
       "   'id': '56bf6b0f3aeaaa14008c9601',\n",
       "   'answers': [{'text': 'Houston, Texas', 'answer_start': 166}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In which decade did Beyonce become famous?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9602',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'In what R&B group was she the lead singer?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9603',\n",
       "   'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What album made her a worldwide known artist?',\n",
       "   'id': '56bf6b0f3aeaaa14008c9604',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"Who managed the Destiny's Child group?\",\n",
       "   'id': '56bf6b0f3aeaaa14008c9605',\n",
       "   'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé rise to fame?',\n",
       "   'id': '56d43c5f2ccc5a1400d830a9',\n",
       "   'answers': [{'text': 'late 1990s', 'answer_start': 276}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What role did Beyoncé have in Destiny's Child?\",\n",
       "   'id': '56d43c5f2ccc5a1400d830aa',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'What was the first album Beyoncé released as a solo artist?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ab',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'When did Beyoncé release Dangerously in Love?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ac',\n",
       "   'answers': [{'text': '2003', 'answer_start': 526}],\n",
       "   'is_impossible': False},\n",
       "  {'question': 'How many Grammy awards did Beyoncé win for her first solo album?',\n",
       "   'id': '56d43c5f2ccc5a1400d830ad',\n",
       "   'answers': [{'text': 'five', 'answer_start': 590}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was Beyoncé's role in Destiny's Child?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b4',\n",
       "   'answers': [{'text': 'lead singer', 'answer_start': 290}],\n",
       "   'is_impossible': False},\n",
       "  {'question': \"What was the name of Beyoncé's first solo album?\",\n",
       "   'id': '56d43ce42ccc5a1400d830b5',\n",
       "   'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}],\n",
       "   'is_impossible': False}],\n",
       " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>207</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>2003</td>\n",
       "      <td>526</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>166</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>276</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                             context          answer_text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           269         286  \n",
       "1           207         226  \n",
       "2           526         530  \n",
       "3           166         180  \n",
       "4           276         286  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squad2 = extract_questions_and_answers(Path(\"squad/train-v2.0.json\"))\n",
    "df_squad2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squad2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_squad2.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad2_train_df, squad2_val_df = train_test_split(df_squad2, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602, 5)\n",
      "(151, 5)\n"
     ]
    }
   ],
   "source": [
    "print(squad2_train_df.shape)\n",
    "print(squad2_val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_data_module = CreateData(squad2_train_df, squad2_val_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "squad_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitk/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Checkpoint directory squad_checkpoints exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"squad_checkpoints\",\n",
    "    filename=\"squad-best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> F1 Score for SqUAD2.0 from previously trained object</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_words_squad2_oldmodel = []\n",
    "ground_truth_squad2_oldmodel = []\n",
    "    \n",
    "for i in range(len(squad2_val_df)) :\n",
    "    predicted_words_squad2_oldmodel.append(generate_answer(squad2_val_df.iloc[i]))\n",
    "    ground_truth_squad2_oldmodel.append(squad2_val_df.iloc[i]['answer_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predicted_words_squad2_old = \",\".join(predicted_words_squad2_oldmodel)\n",
    "eval_ground_truth_squad2_old = \",\".join(ground_truth_squad2_oldmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of our model ->  95.62794684954994\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score of our model -> \",100*f1_score(eval_predicted_words_squad2_old, eval_ground_truth_squad2_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see the F1 Score we are getting for this model is actually slightly better than the one on BioASQ dataset </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING THE SAME MODEL WE USED TO GENERATE ANSWERS FOR SQUAD 2.00 DATASET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> WE WILL USE THE SAME GENERATE METHOD AS DEFINED PREVIOUSLY FOR BIOASQ DATASET </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For what movie did Beyonce receive  her first Golden Globe nomination?'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[20]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dreamgirls'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"B'Day\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What city was Beyoncé's elementary school located in?\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[25]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fredericksburg'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fredericksburg'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When did The Mamas make their debut?'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[35]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the 2006 BET Awards'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)      #Here we can see that model gets confused between same entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What percentage of people were positive about Beyonce's endorsement of Pepsi?\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[150]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70 per cent'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see that we are getting expected results but the model can get confused sometimes and does nor predict the exact same answer but even though it is not the exact answer, it is still the correct answer except for a few cases </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING NEW MODEL FOR SQUAD2.0 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer2 = pl.Trainer(checkpoint_callback=checkpoint_callback, max_epochs=NUM_EPOCHS, gpus=1, progress_bar_refresh_rate = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = QAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ced73f9aa8b46c0b448907c5d65f219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b315ef92c1fe4a33a9721915b3d1a996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 150: val_loss reached 0.65332 (best 0.65332), saving model to \"/data/user/ankitk/NLP/squad_checkpoints/squad-best-checkpoint-v4.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 301: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 452: val_loss reached 0.16294 (best 0.16294), saving model to \"/data/user/ankitk/NLP/squad_checkpoints/squad-best-checkpoint-v4.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 603: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 754: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 905: val_loss was not in top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.fit(model2, squad_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0563ac4d0a064338aad224857c986b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.05630814656615257, 'test_loss_epoch': 0.17532028257846832}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.17532028257846832, 'test_loss': 0.05630814656615257}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer2.test(ckpt_path = \"squad_checkpoints/squad-best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model2 = QAModel.load_from_checkpoint(\"squad_checkpoints/squad-best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model2.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding=tokenizer(question[\"question\"], question['context'], max_length = 396, padding=\"max_length\",\n",
    "                            truncation=\"only_second\", return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    \n",
    "    generated_ids = trained_model2.model.generate(input_ids=source_encoding[\"input_ids\"], attention_mask=source_encoding[\"attention_mask\"],\n",
    "                                                num_beams=1, max_length=80, repetition_penalty=2.5,\n",
    "                                                length_penalty = 1.0, early_stopping=True, use_cache=True)\n",
    "\n",
    "    preds = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "             for generated_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)\n",
    "\n",
    "#num_beans = 1 for greedy search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will again check our answer text for some of the random questions manually which we tested above </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For what movie did Beyonce receive  her first Golden Globe nomination?'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[20]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dreamgirls'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dreamgirls'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)  # Predicted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What city was Beyoncé's elementary school located in?\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[25]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fredericksburg'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fredericksburg'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When did The Mamas make their debut?'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[35]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the 2006 BET Awards'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2006 BET Awards'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)      #Here we can see that model gets confused between same entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What percentage of people were positive about Beyonce's endorsement of Pepsi?\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad = squad2_val_df.iloc[150]\n",
    "sample_question_squad[\"question\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question_squad[\"answer_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_answer(sample_question_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad2_val_df.to_csv(r'./SQUAD2_VALIDATION.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> F1 Score for newly trained SqUAD2.0 Model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_words_squad2_newmodel = []\n",
    "ground_truth_squad2_newmodel = []\n",
    "    \n",
    "for i in range(len(squad2_val_df)) :\n",
    "    predicted_words_squad2_newmodel.append(generate_answer(squad2_val_df.iloc[i]))\n",
    "    ground_truth_squad2_newmodel.append(squad2_val_df.iloc[i]['answer_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_predicted_words_squad_new = \",\".join(predicted_words_squad2_newmodel)\n",
    "eval_ground_truth_squad_new = \",\".join(ground_truth_squad2_newmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of our model ->  97.29139362166885\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score of our model -> \",100*f1_score(eval_predicted_words_squad_new, eval_ground_truth_squad_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reference for Evaluate function - https://github.com/vibalcam/nlp-qa-squad-bioasq/blob/master/evaluate.py </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp2021]",
   "language": "python",
   "name": "conda-env-nlp2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
